install.packages("devtools")
install.packages("KernSmooth")
library("KernSmooth", lib.loc="~/R/x86_64-pc-linux-gnu-library/3.3")
install.packages("rnn")
library(rnn)
trainr
?trainr
X1 = sample(0:127, 7000, replace=TRUE)
X2 = sample(0:127, 7000, replace=TRUE)
Y <- X1 + X2
X1 <- int2bin(X1, length=8)
X2 <- int2bin(X2, length=8)
Y  <- int2bin(Y,  length=8)
X <- array( c(X1,X2), dim=c(dim(X1),2) )
model <- trainr(Y=Y,
X=X,
learningrate   =  0.1,
hidden_dim     = 10,
start_from_end = TRUE )
plot(colMeans(model$error),type='l',
xlab='epoch',
ylab='errors'                  )
A1 = int2bin( sample(0:127, 7000, replace=TRUE) )
A2 = int2bin( sample(0:127, 7000, replace=TRUE) )
A <- array( c(A1,A2), dim=c(dim(A1),2) )
B  <- predictr(model,
A     )
A1 <- bin2int(A1)
A2 <- bin2int(A2)
B  <- bin2int(B)
hist( B-(A1+A2) )
detach("package:rnn", unload=TRUE)
install.packages("RSNNS")
install.packages("hydroGOF")
?mlp
??mlp
??mlp
View(iris)
View(outputs)
View(predictions)
View(inputs)
errror
error
patset
snnsObject
res
patset
View(iris)
View(iris)
class(iris)
View(outputs)
class(output)
class(outputs)
class(inputs)
View(predictions)
View(outputs)
View(outputs)
View(predictions)
View(inputs)
install.packages("sigmoid")
library("sigmoid", lib.loc="~/R/x86_64-pc-linux-gnu-library/3.3")
a <- seq(-10,10)
( b <- sigmoid(a) )
plot(b)
hist( a - sigmoid(b, inverse=TRUE) )
( c <- sigmoid(a, SoftMax=TRUE) )
plot(c)
args(sigmoid)
?sigmoid
??sigmoid
x = seq(1,5, by=0.05)
qplot(sigmoid(x))
x = seq(1,5, by=0.05)
plot(sigmoid(x))
plot(sigmoid(c))
x <- seq(-5, 5, 0.01)
plot(x, sigmoid(x), col='blue')
plot(x,name, col='blue')
plot(x, sigmoid(x), col='red')
summary(model)
library("nnet")
library(nnet)
mod <- nnet(Y1 ~ X1 + X2 + X3, data = neuraldat, size = 1
)
library(nnet)
mod <- nnet(Y1 ~ X1 + X2 + X3, data = neuraldat, size = 10)
library(NeuralNetTools)
data(neuraldat)
library(nnet)
mod <- nnet(Y1 ~ X1 + X2 + X3, data = neuraldat, size = 10)
par(mar = numeric(4))
plotnet(mod)
library(nnet)
mod <- nnet(Y1 ~ X1 + X2 + X3+ X4, data = neuraldat, size = 10)
nerualdat
neuraldat
head(neuraldat)
library(nnet)
mod <- nnet(Y1 ~ X1 + X2 + X3+ Y1, Y2, data = neuraldat, size = 10)
par(mar = numeric(4))
plotnet(mod)
plotnet(mod)
?neuralnet
??neuralnet
?rnn
??rnn
?lapply
?slip
?split
args(lapply)
str(split)
x <- c(rnorm(10), runif(10),rnorm(10,1))
f <- gl(3,10)
split(x,gl)
split(x,f)
f
?gl
a <-gl(5,1)
a
a <-gl(5,5)
a
gl(10,5)
a <- gl(2,2,20)
a
lapply(split(x,f),mean)
library(datasets)
head(airquality)
s <- split(airquality, airquality$Month)
lapply(s, function(x) colMeans (x[,c("Ozone", "Solar.R", "Wind")]))
sapply(s, function(x) colMeans (x[,c("Ozone", "Solar.R", "Wind")]))
sapply(s, function(x) colMeans (x[,c("Ozone", "Solar.R", "Wind")] na.rm = TRUE))
sapply(s, function(x) colMeans (x[,c("Ozone", "Solar.R", "Wind")] na.rm = TRUE))
sapply(s, function(x) colMeans (x[,c("Ozone", "Solar.R", "Wind")], na.rm = TRUE))
?interaction
swirl()
swirl::play()
library(swirl)
swirl()
1
swirl()
main
quit
quit
main()
quit()
library("swirl")
swirl()
main()
head(flags)
dim(flags)
viewinfo()
class(flags)
cls_list <- lapply(flags, class)
cls_list
class(cls_list)
as.character(cls_list)
cls_vect <- sapply
cls_vect <- sapply(flags, class)
cls_vect
class(cls_vect)
sum(flags$orange)
flag_colors <- flags[,11:17]
head(flag_colors)
lapply(flag_colors, sum)
sapply(flag_colors,sum)
sapply(flag_colors,mean)
flag_shapes <- flags[,19:23]
lapply(flag_shapes,range)
shape_mat <- sapply(flag_shapes,range)
shape_mat
class(shape_mat)
unique(c(3,4,5,5,5,6,6,))
unique(c(3,4,5,5,5,6,6,4))
unique(c(3,4,5,5,5,6,6))
unique_vals <- lapply(flags,unique)
unique_vals
lapply(unique_vals,length)
sapply(unique_vals,length)
sapply(flags,unique)
lapply((unique_vals, function(elem) elem[2])
lapply((unique_vals,function(elem) elem[2])
lapply((unique_vals, function(elem) elem[2])
unique_vals
lapply(unique_vals, function(elem) elem[2])
main()
main()
sapply(flags,unique)
vapply(flags,unique, numeric(1))
ok()
sapply(flags,class)
sapply(flags,class, character(1))
ok()
vapply(flags,class, character(1))
?tapply
flags$landmass
table(flags$landmass)
table(flags$animate)
tapply(flags$animate,flags$landmass , mean)
tapply(flags$population,flags$red, summary)
tapply(flags$population,flags$landmass, summary)
library(datasets)
data(iris)
library(datasets)
data(iris)
?iris
a <- iris$Sepal.Length
mean(a)
apply(iris, 1, mean)
rowMeans(iris[, 1:4])
colMeans(iris)
apply(iris, 2, mean)
apply(iris[, 1:4], 1, mean)
apply(iris[, 1:4], 2, mean)
data(mtcars)
?mtcars
sapply(mtcars, cyl, mean)
mean(mtcars$mpg, mtcars$cyl)
tapply(mtcars$mpg, mtcars$cyl, mean)
tapply(mtcars$cyl, mtcars$mpg, mean)
sapply(split(mtcars$mpg, mtcars$cyl), mean)
with(mtcars, tapply(mpg, cyl, mean))
apply(mtcars, 2, mean)
lapply(mtcars, mean)
with(mtcars, tapply(mpg, cyl, mean))
?abs
str(abs)
a <- with(mtcars, tapply(mpg, cyl, mean))
dim(a)
class(a)
a[0,1]
a[1,1]
a[,1]
a[2,]
a[2]
a[2][1]
a[2][2]
a[2][2]
a[3]
abs(15.1)
lapply(a,abs)
sapply(a,abs)
b <- sapply(a,abs)
b
dim(b)
class(b)
b <- lapply(a,abs)
class(b)
b[1]
b$`8` - b$`4`
b$`4` - b$`8`
debug(ls)
ls
debug(ls)
ls
ls
ls
ls
ls
ls
ls
ls
ls
ls
ls
ls
ls
install_from_swirl("Getting and Cleaning Data")
library(swirl)
install_from_swirl("Getting and Cleaning Data")
?xml
??xml
install.packages("XLConnect")
install.packages(c("xlsx", "XLConnect"))
install.packages("xlsx")
R CMD javareconf -e
}
if(!file.exists("camera.csv")){
file.create("camera.csv")
}
url <- "https://data.baltimorecity.gov/api/views/dz54-2aru/rows.csv?accessType=DOWNLOAD"
download.file(url, destfile = "camera.csv", method = "curl")
cameraData <- read.csv("camera.csv")
names(cameraData)
tolower(names(cameraData))
splitNames <- strsplit(names(cameraData), "\\.")
splitNames[[5]]
splitNames[[6]]
splitNames[[6]][1]
firstElement <- function(x){x[1]}
sapply(splitNames,firstElement)
names(cameraData)<- tolower(names(cameraData))
sapply(splitNames,firstElement)
splitNames <- strsplit(names(cameraData), "\\.")
splitNames[[6]][1]
firstElement <- function(x){x[1]}
sapply(splitNames,firstElement)
grep("Almeda", cameraData$intersection)
grep("Almeda", cameraData$intersection)
grep("Alameda", cameraData$intersection)
table(grepl(grep("Alameda", cameraData$intersection) ))
table(grepl("Alameda", cameraData$intersection) )
d1 = date()
d1
d2 = Sys.Date()
d2
class(d2)
class(d1)
format(d2, "%a %b %d")
format(d2, "%A %m %y")
format(d2, "%d %B %Y")
X <- c("1jan1960","2jan1960"); z = as.Date(x,"%d%b%Y")
X <- c("1jan1960","2jan1960"); z = as.Date(x,"%d%b%Y")
x <- c("1jan1960","2jan1960"); z = as.Date(x,"%d%b%Y")
x <- c("1jan1960","2jan1960"); z = as.Date(x,"%d%b%Y")
z
z[1]-z[2]
weekdays(d2)
months(d2)
julian(d2)
library(lubridate); ymd("20140108")
install.packages("lubridate")
library(lubridate); ymd("20140108")
mdy("08/04/2013")
dmy("03-04-2013")
?Sys.timezone
?POSIXt
library(swirl)
swirl()
main()
Sys.getlocale("LC_TIME")
libray
library(lubridate)
help(package = lubridate)
today()
this_day <- today()
this_day
year(this_day)
wday(this_day)
wday(this_day, label = T)
wday(this_day, label = TRUE)
this_moment <- now()
this_moment
hour(this_moment)
ymd("1989-05-17")
my_date <- ymd("1989-05-17")
my_date
class(my_date)
ymd("1980 May 17")
ymd("1989 May 17")
mdy("March 12, 1975")
dmy(25081985)
ymd("192012")
ymd("1920-1-2")
dt1
ymd_hms(dt1)
hour("03:22:14")
skip()
dt2
ymd(dt2)
update(this_moment, hours = 8, minutes = 34, seconds = 55)
this_moment
update(this_moment, minutes = 53, seconds = 1)
update(this_moment, hours = 0, minutes = 53, seconds = 1)
update(this_moment, hours = 10, minutes = 16, seconds = 0)
update(this_moment, hours = 10, minutes = 16, seconds = 0)
skip()
this_moment
?now()
now
now("America/New_Yok)
)""
""
noe("America/New_York")
now("America/New_York")
nyc <- now("America/New_York")
nyc
depart <- nyc + days(2)
depart
depart <- update(depart, hours = 17, minutes = 34)
depart
arrive <- nyc + hours(15) + minutes(50)
arrive <- depart + hours(15) + minutes(50)
?with_tz
with_tz(arrive, tzone = "Asia/Hong_Kong")
with_tz(arrive, "Asia/Hong_Kong")
arrive <- with_tz(arrive, "Asia/Hong_Kong")
arrive
skip()
last_time
?interval
how_long <- interval(arrive)
skip()
how_long <- interval(last_time, arrive)
as.period(how_long)
stopwatch()
setwd
setwd("~/Desktop/R programming/Data Science Specalization Coursera/Course 3")
list.files()
surveyData <- read.csv("survey.csv")
names(surveyData)<- tolower(names(surveyData))
names(surveyData)
splitList <- strsplit(names(surveyData) == "wgtp")
?strsplit
splitList <- strsplit(names(surveyData), "wgtp")
splitList[[123]]
splitList
View(surveyData)
View(surveyData)
strsplit(names(data), "wgtp")[123]
strsplit(names(surveyData), "wgtp")[123]
if (!file.exists("survey1.csv")) {
file.create("survey1.csv")
}
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv"
download.file(fileUrl, destfile="survey1.csv", method="curl")
surveyData <- read.csv("survey1.csv")
names(surveyData)<- tolower(names(surveyData))
splitList <- strsplit(names(surveyData), "wgtp")
splitList[[123]]
if (!file.exists("GDP.csv")) {
file.create("GDP.csv")
}
fileUrl2 <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv"
download.file(fileUrl2, destfile="GDP.csv", method="curl")
GDP <- read.csv("survey1.csv")
names(GDP)
View(GDP)
gdpData <- read.csv("survey1.csv", stringsAsFactors = FALSE, skip=4, nrows=215, col.names=c("CountryCode", "Rank", "Empty1", "Fullname", "GDP", "Empty3", "Empty4", "Empty5", "Empty6", "Empty7"))
downloadDir <- './data'
if (!file.exists(downloadDir)) {
dir.create(downloadDir)
}
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv "
dataFile <- file.path(paste(downloadDir, "getdata_data_GDP.csv", sep="/"))
download.file(fileUrl, destfile=dataFile, method="curl")
gdpData <- read.csv(dataFile, stringsAsFactors = FALSE, skip=4, nrows=215, col.names=c("CountryCode", "Rank", "Empty1", "Fullname", "GDP", "Empty3", "Empty4", "Empty5", "Empty6", "Empty7"))
gdpData$GDP <- gsub(x=gdpData$GDP, pattern = ",", replacement = "")
gdpData$GDP <- as.numeric(gdpData$GDP)
mean(gdpData$GDP, na.rm = TRUE)
length(grep(pattern = "^United", gdpData$Fullname))
library(dplyr)
#Question 4
edu <- read.csv("edu.csv")
gdp <- read.csv("gdp.csv", header = T)
gdp <- tbl_df(gdp)
# Cleaning to get tidy data
gdp <- rename(gdp, CountryCode = X , Ranking = Gross.domestic.product.2012, Economy = X.2 , USD = X.3 )
gdp <- select(gdp, CountryCode, Ranking, Economy)
gdp <- gdp[-(1:4),]
edu <- tbl_df(edu)
mergedData <- merge(gdp, edu, by.x="CountryCode", by.y="CountryCode", all=FALSE)
length(mergedData$Special.Notes[grep("Fiscal year end: June", mergedData$Special.Notes)])
library(quantmod)
install.packages("quantmod")
library(quantmod)
amzn = getSymbols("AMZN",auto.assign=FALSE)
sampleTimes = index(amzn)
years <- format(sampleTimes, "%Y")
sampleTimes <-sampleTimes[years==2012]
length(sampleTimes)
length(weekdays(sampleTimes)[weekdays(sampleTimes)=="Monday"])
